# Course ‚Äì 1 Intro to RAG

Mini-project, notes, and labs for this course.

## Deliverables
- [ ] Lab code
- [ ] Project demo
- [ ] Notes summary

## üß† Key Concepts & Notes

### Module 1 ‚Äì Foundations of GenAI & Prompt Engineering

## üß† Lesson: Introduction to Generative AI

- Two main types of AI: **Discriminative** (classify, analyze) vs **Generative** (create, generate)
- **Discriminative AI** = tells if something is A or B (e.g., puppy or fried chicken)
- **Generative AI** = creates new content (text, images, audio, code)
- **Foundation Models** = broad, general-purpose models trained on massive data (e.g., LLMs like GPT, Gemini)
- **LLMs** = a type of Foundation Model focused on generating human-like language

### Reflection
- Tools like ChatGPT and Gemini are **hybrid systems**‚Äîthey use **generative models** as the core, but can handle discriminative tasks via fine-tuning or plugins.

## üß† Lesson: What are Generative AI Models?

- **LLMs** = (Large Language Models) An application of a **Foundation Model**
- **Foundation Model** = A type of general-use AI that can be used to perform very specific applications due it being trained on large amounts of unstructured data.
- **Foundation Models** are also Generative AI
- **Tuning** = When you label your data to better suit your application
- When using lowly labelled or unlabelled data, prompting can be used (prompt engineering applicable here)
- **FM ADVs** = Performance and Productivity (both due to large traita-set)
- **FM dAVDs** = Costly and not *as* Trustworthy
- **FM Applications** = Not just LLMs. Code, Vision, Chemistry, Climate Change.

## Reflection
- There's a lot of hype around LLMs recently. All the other applications of FMs seem to be overlooked but I can understand why. I feel as well that LLMs are where the money is so that can be a major contributor as well.

## üß† Lesson: What is NLP (Natural Language Processing)?

- **NLP** = When you ask/train a computer to understand and comprehend human language
- **Unsctructured Speech** = How computers interpret how we speak or how we speak naturally.
- **Structured Speech** = How computers understand what we say in a form using tags (<>) for example.
- NLP is the bridge or translator between converting from unstructured speech to structured speech and vice versa
- **NLU** = Natural Language Undersatnding - Unstructured Speech to Structured Speech
- **NLG** = Natural Language Generation - Structured Speech to Unstructured Speech
- **NLP Uses** = Machine Translation, Virtual Assistants/Chatbots, Sentiment Analysis, Spam Detection
- NLP is not a single algorithm but a bag of tools used to "solve" the use cases
- **SOME tools of NLP** = First we need input from text or speech-to-text then **Tokenization** (break the text up into smaller parts basically) then **Stemming** (finding the root word of a token) or **Lemmatization** (finding the root meaning of a token), **Part of Speech Tagging** (finding the context of a token) then **N.E.R (Named Entity Recognition)** (giving a token meaning e.g. Trinidad & Tobago - entity: Caribbean Country vs Zion - entity: name of person)

## Relfection
- Cools cools. Before this I was a bit shaky about what NLP is but I believe I have a decent grasp on it now and how it plays a part in LLMs. There of course needs to be an NLP step to do NLU then NGU after the job is done.

### Module 2 ‚Äì LangChain Core Concepts



### Module 3 ‚Äì Flask App with LangChain

---

## üß™ Lab / Mini-Project

### Overview

### Features
---

## üîÅ Reflection & Learnings
